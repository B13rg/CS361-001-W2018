\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\graphicspath{ {./} }


\title{Talkatiel Software Requirements and Planning}
\author{Brendan Byers, Ryan Sisco, Iliana J, Aidan Grimshaw}
\date{\today}

\begin{document}
\begin{center}
      \Large\textbf{User Stories and Set-up Assignment}\\
      \large\textit{Brendan Byers, Ryan Sisco, Iliana J, Aidan Grimshaw, Yufei Zeng}\\
      \large{byersbr, siscor, javieri, grimshaa, zengyu}\\
   \end{center}

\tableofcontents
\section{Product Release}
   \subsection{Server Side Implimentation}
   Currently the server code can be downloaded and run locally.  By cloning the repository located at https://github.com/B13rg/Talkatiel_API.git one can run the server.  There is also extensive documentation detailing all the steps that need to be taken to run the server.  There is also a SQL script that will create a database when run.  This can be used to create a database for use on a different engine.  Currently it is configured to run on the localhost on port 5002.  This can be tested to navigating to 127.0.0.1:5002/Posts/New where you can see the raw Json output of a post.  In the repository there is also an sqlite database that is run alongside the python code.  This will connect with the python to respond to different sql queries.  It is fully functioning, and the only thing left to do is test it, and find a permanent URL.
   \subsection{Client Side Implimentation}
\section{User Story}
      \subsection{Add a post}
      The server side group worked on adding this ability to the api.  Currently a user is able to POST a json string to the server.  The server takes the json and decodes a post object out of it.  Then the post is passed into the database to be retrieved later.  Implimentation of this took 2 hours.  Currently we still need to test the implimentation with more extensive unit tests.      
      \subsection{Add a Comment}
      The server side group worked on adding this ability to the api.  Currently a user is able to POST a json string to the server.  The server takes the json and decodes a comment object out of it.  Then the post is passed into the database to be retrieved later.  Implimentation of this took 1 hour.  It was extremely similar to adding a post.  Currently we still need to test the implimentation with more extensive unit tests.
      \subsection{Like/Dislike}
      The server side group implimentated a way to like and dislike posts.  It is done by throwing a 1 or a 0 to the url of the post.  This will look like this: https://Talkatiel.com/Posts/<int:postID>/<int:voteType> .  The server decodes the url and applies the proper vote to the given post.  Implimentation took around 3 hours.  Currently there needs to be more testing done.
      \subsection{Report}
      Server group implimented this through the API.  In this case, when the server recieves a report about a post, the postID reporting userID, and report message content will be added to a special \"reports\" table in the database that will be able to viewed by admins later.The implimentation took around 3 hours.  Only thing left to do is add a way for admins to access the reports in an orderly way.
      \subsection{Delete}
      The server group worked on the server side implimentation of this.  In order to delete a post a url is GET requested with the postID.  The id is decoded, and the given post is marked as not visible.  When posts are retrieved from the database for users, the deleted posts are ignored.  The work on this took 2 hours.  It was closely tied to the refresh function.  Currently we need to impliment some form of authentication so only requests with the correct key can delete a post.
      \subsection{Refresh}
      The server group worked on this.  In order to refresh and retrieve new posts on the deivce, one of 3 urls are sent GET requests.  The URL's determine the type of sort the post are in when returned.  When retrieving posts for the user, the server first checks it's cache.  The posts for any given category are only calculated once every two minutes.  Each time it fetches it will store what it returns in the cache.  This is so we don't overload the database with too many requests.  The only exception in when fetching \"New\" posts. There is no caching done for fetching them because theres no calculating to be done.  Currently the API is functional.  Implimentation of this portion took 6 hours.  The only thing left is testing.
      \subsection{Sort}
      The server side implimeted the different types of sorting.  The posts are fetched from the database based on post date.  When fetching \"Best\" or \"Top\", the order of posts must be calculated.  For the \"Top\" category, the best posts of the last 24 hours are at the top.  They are ranked based on upvotes minus downvotes.  They are only considered if they're marked as visible.  This calculation takes place every 2 minutes due to the use of a cache.  For fetching \"Best\", the post order is calculated every 2 minutes thanks to the cache.  This cuts down on how many requests we hit the database wth.  The calculation factors in post time and  number of upvotes and downvotes.  This is a potentially expensive alculation given post activity, so the use of the cache was really important for this set.  The total time for implimentation took around 7 hours.  The only thing left is to test the server side of things.
      \subsection{Add to Favorites}
      \subsection{Offline Favorites}
      \subsection{Offline Compatability}
      \subsection{View Newly Created Post}
      Server side worked on this.  Because of how sorting by new is implimented, a user is able to see their posts immedietly.  This is because there is no caching done on that sorting method.  This makes it so the database is queried every time.  If the server load was a lot, it would still be acceptable to cache things for even 5 minutes to lighten the load on the server.
      \subsection{Collapse Post Responses}
      \subsection{Secure HTTPS Connection}
      In order to get a secure https connection, we need to get a security certificate signed by a certificate authority.  We havn't chosen where the code will be hosted.  Currently we are considering either trying to use the university services or a third party.  I believe that we may be ably to host the API server using virtual environments, which may allow us to run a server on that port.  Time spent was 1 hour.  We still need to finalize design choices to recieve the certificate.
      \subsection{Save Website as App on Phone}
      \subsection{Responsive Web Page}
\section{Tests}
\section{Design Changes and rationale}
For the most part the server group stayed very close to original design.  To design the database we worked off the UML design digrams we designed earlier.  This allowed us to see what fields we needed to include for each table.  We added an extra table not originally in the design doc to handle reports.  We found there was no way to keep track of reports server side, so we added a table to handle it.  It keeps track of the user who reported it, the post in question, and the text of the users report.  By having it's own table it can also be queried seperatly instead of having to sort through who knows what.
\section{Meeting Report}





\end{document}
